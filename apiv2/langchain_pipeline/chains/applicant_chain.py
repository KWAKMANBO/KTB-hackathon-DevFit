"""
êµ¬ì§ì ë¶„ì„ ì²´ì¸

íŒŒì´í”„ë¼ì¸ íë¦„:
1. í…ìŠ¤íŠ¸ ê¸°ë°˜: ì´ë ¥ì„œ í…ìŠ¤íŠ¸ â†’ í”„ë¡œí•„ ë¶„ì„ â†’ JSON ì¶œë ¥
2. S3 PDF ê¸°ë°˜: S3 PDF â†’ Gemini Files API â†’ í”„ë¡œí•„ ë¶„ì„ â†’ JSON ì¶œë ¥
3. ë¡œì»¬ PDF ê¸°ë°˜: ë¡œì»¬ PDFë“¤ â†’ Gemini Files API â†’ í†µí•© ë¶„ì„ â†’ JSON ì¶œë ¥

S3/ë¡œì»¬ PDF ì—°ë™ ì‹œ google-genai SDKë¥¼ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤ (PDF multimodal ì§€ì›)
"""

import logging
import json
import re
from typing import Any, Optional

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

from apiv2.langchain_pipeline.config import (
    GOOGLE_API_KEY,
    S3_BUCKET_NAME,
    S3_REGION,
    AWS_ACCESS_KEY_ID,
    AWS_SECRET_ACCESS_KEY,
)
from apiv2.langchain_pipeline.utils.schema_loader import get_schema_for_prompt
from apiv2.langchain_pipeline.utils.db_handler import DatabaseHandler
from apiv2.langchain_pipeline.prompts import applicant_analyze

logger = logging.getLogger(__name__)


def parse_json_response(response) -> dict:
    """LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹± (robust)"""
    original_response = response  # ë””ë²„ê¹…ìš© ì›ë³¸ ì €ì¥

    # AIMessage ë˜ëŠ” content ì†ì„±ì´ ìˆëŠ” ê°ì²´ ì²˜ë¦¬
    if hasattr(response, 'content'):
        text = response.content
    else:
        text = str(response)

    text = text.strip()

    # ```json ... ``` ë˜ëŠ” ``` ... ``` ì œê±°
    if "```json" in text:
        match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
        if match:
            text = match.group(1)
    elif "```" in text:
        match = re.search(r'```\s*(.*?)\s*```', text, re.DOTALL)
        if match:
            text = match.group(1)

    # JSON ê°ì²´ ì‹œì‘ì  ì°¾ê¸°
    first_brace = text.find('{')
    if first_brace != -1:
        text = text[first_brace:]

    # JSON ê°ì²´ ëì  ì°¾ê¸°
    last_brace = text.rfind('}')
    if last_brace != -1:
        text = text[:last_brace + 1]

    # Trailing comma ì œê±° (LLMì´ ìì£¼ ë§Œë“œëŠ” ì˜¤ë¥˜)
    text = re.sub(r',\s*}', '}', text)
    text = re.sub(r',\s*]', ']', text)

    # JSON íŒŒì‹± ì‹œë„ (ì—¬ëŸ¬ ë°©ë²•)
    try:
        # 1ì°¨ ì‹œë„: í‘œì¤€ json.loads
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    try:
        # 2ì°¨ ì‹œë„: raw_decode (extra data ë¬´ì‹œ)
        decoder = json.JSONDecoder()
        result, _ = decoder.raw_decode(text)
        return result
    except json.JSONDecodeError as e:
        logger.error("=" * 70)
        logger.error(f"[applicant_chain] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        logger.error("=" * 70)
        logger.error(f"ì—ëŸ¬ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
        logger.error("-" * 70)

        # ì—ëŸ¬ ìœ„ì¹˜ ì£¼ë³€ í…ìŠ¤íŠ¸ í‘œì‹œ
        lines = text.split('\n')
        error_line = e.lineno - 1
        start_line = max(0, error_line - 2)
        end_line = min(len(lines), error_line + 3)

        logger.error("ì—ëŸ¬ ìœ„ì¹˜ ì£¼ë³€:")
        for i in range(start_line, end_line):
            prefix = ">>> " if i == error_line else "    "
            line_content = lines[i][:200] + "..." if len(lines[i]) > 200 else lines[i]
            logger.error(f"{prefix}{i+1:4d} | {line_content}")

        logger.error("-" * 70)
        logger.error(f"ì›ë³¸ ì‘ë‹µ íƒ€ì…: {type(original_response).__name__}")
        logger.error(f"ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} chars")
        logger.error("=" * 70)
        raise


class ApplicantAnalysisChain:
    """
    êµ¬ì§ì ë¶„ì„ ì²´ì¸

    ë‘ ê°€ì§€ ë¶„ì„ ëª¨ë“œ ì§€ì›:
    1. run(): í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)
    2. run_from_s3(): S3 PDF ê¸°ë°˜ ë¶„ì„ (Gemini multimodal)
    """

    def __init__(
        self,
        model_name: str = "gemini-2.0-flash-exp",
        temperature: float = 0.0,
        save_to_db: bool = True
    ):
        """
        Args:
            model_name: Gemini ëª¨ë¸ëª…
            temperature: ìƒì„± ì˜¨ë„
            save_to_db: DB ì €ì¥ ì—¬ë¶€
        """
        logger.info(f"Initializing ApplicantAnalysisChain with model='{model_name}', temperature={temperature}, save_to_db={save_to_db}")
        self.model_name = model_name
        self.temperature = temperature

        # LangChain LLM (í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ìš©)
        self.llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=GOOGLE_API_KEY,
            temperature=temperature,
        )

        self.save_to_db = save_to_db
        self.db = DatabaseHandler() if save_to_db else None

        # PDF ë¡œë” (ì§€ì—° ì´ˆê¸°í™”)
        self._s3_loader = None
        self._local_loader = None
        self._uploaded_file = None
        self._uploaded_files: list = []  # ì—¬ëŸ¬ íŒŒì¼ ì¶”ì ìš©

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        self._setup_prompts()
        logger.info("ApplicantAnalysisChain initialized successfully.")

    def _setup_prompts(self):
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        self.analyze_prompt = ChatPromptTemplate.from_messages([
            ("system", applicant_analyze.SYSTEM_MESSAGE),
            ("human", applicant_analyze.HUMAN_MESSAGE_TEMPLATE),
        ])

        self.json_parser = JsonOutputParser()

    def _get_s3_loader(self):
        """S3 PDF ë¡œë” ì§€ì—° ì´ˆê¸°í™”"""
        if self._s3_loader is None:
            from apiv2.langchain_pipeline.loaders.s3_pdf_loader import S3PDFLoader

            self._s3_loader = S3PDFLoader(
                bucket_name=S3_BUCKET_NAME,
                gemini_api_key=GOOGLE_API_KEY,
                aws_region=S3_REGION,
                aws_access_key_id=AWS_ACCESS_KEY_ID or None,
                aws_secret_access_key=AWS_SECRET_ACCESS_KEY or None,
            )

        return self._s3_loader

    def _get_local_loader(self):
        """ë¡œì»¬ PDF ë¡œë” ì§€ì—° ì´ˆê¸°í™”"""
        if self._local_loader is None:
            from apiv2.langchain_pipeline.loaders.local_pdf_loader import LocalPDFLoader

            self._local_loader = LocalPDFLoader(
                gemini_api_key=GOOGLE_API_KEY
            )

        return self._local_loader

    async def analyze(self, resume_text: str) -> dict[str, Any]:
        """
        ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ í…ìŠ¤íŠ¸ ë¶„ì„ (LangChain ì‚¬ìš©)

        Args:
            resume_text: ì´ë ¥ì„œ ë˜ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ í…ìŠ¤íŠ¸

        Returns:
            êµ¬ì§ì í”„ë¡œí•„ ë¶„ì„ ê²°ê³¼ (JSON)
        """
        schema = get_schema_for_prompt("applicant_schema")

        chain = self.analyze_prompt | self.llm | self.json_parser

        result = await chain.ainvoke({
            "resume_text": resume_text,
            "output_schema": schema,
        })

        return result

    async def analyze_pdf(self, s3_key: str) -> dict[str, Any]:
        """
        S3ì˜ PDF íŒŒì¼ ë¶„ì„ (Gemini Files API ì§ì ‘ ì‚¬ìš©)

        Args:
            s3_key: S3 ê°ì²´ í‚¤ (ì˜ˆ: "{token}/resume.pdf")

        Returns:
            êµ¬ì§ì í”„ë¡œí•„ ë¶„ì„ ê²°ê³¼ (JSON)
        """
        import time
        from google import genai
        from google.genai import types

        total_start = time.time()
        logger.info(f"ğŸ‘¤ [Applicant] ë¶„ì„ ì‹œì‘ | S3 Key: {s3_key}")

        loader = self._get_s3_loader()

        try:
            # 1. S3 â†’ Gemini ì—…ë¡œë“œ
            step_start = time.time()
            logger.info("ğŸ‘¤ [Applicant] 1/3 S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ â†’ Gemini ì—…ë¡œë“œ ì¤‘...")
            self._uploaded_file = loader.load_from_s3(s3_key)
            logger.info(f"ğŸ‘¤ [Applicant] 1/3 ì—…ë¡œë“œ ì™„ë£Œ ({time.time() - step_start:.1f}ì´ˆ)")

            if self._uploaded_file.state != 'ACTIVE':
                raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {self._uploaded_file.state}")

            # 2. ìŠ¤í‚¤ë§ˆ ë¡œë“œ (Gemini ì§ì ‘ ì‚¬ìš©ì´ë¯€ë¡œ ì´ìŠ¤ì¼€ì´í”„ ë¶ˆí•„ìš”)
            schema = get_schema_for_prompt("applicant_schema", escape_braces=False)

            # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""{applicant_analyze.SYSTEM_MESSAGE}

ë‹¤ìŒ PDF ë¬¸ì„œ(ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤)ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

## ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ
{schema}

{applicant_analyze.HUMAN_MESSAGE_TEMPLATE.replace("{resume_text}", "[ì²¨ë¶€ëœ PDF ë¬¸ì„œ ì°¸ì¡°]").replace("{output_schema}", "")}

ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

            # 4. Geminiì— PDF + í”„ë¡¬í”„íŠ¸ ì „ì†¡
            step_start = time.time()
            logger.info("ğŸ‘¤ [Applicant] 2/3 Gemini LLM ë¶„ì„ ì¤‘...")
            client = genai.Client(api_key=GOOGLE_API_KEY)

            # URI ë¬¸ìì—´ì´ ì•„ë‹Œ types.Part.from_uri()ë¡œ ë³€í™˜í•´ì•¼ Geminiê°€ PDFë¥¼ ì¸ì‹í•¨
            pdf_part = types.Part.from_uri(
                file_uri=self._uploaded_file.uri,
                mime_type="application/pdf"
            )

            response = client.models.generate_content(
                model=self.model_name,
                contents=[pdf_part, prompt]
            )
            logger.info(f"ğŸ‘¤ [Applicant] 2/3 LLM ë¶„ì„ ì™„ë£Œ ({time.time() - step_start:.1f}ì´ˆ)")

            # 5. JSON íŒŒì‹±
            step_start = time.time()
            logger.info("ğŸ‘¤ [Applicant] 3/3 JSON íŒŒì‹± ì¤‘...")
            result = parse_json_response(response.text)
            logger.info(f"ğŸ‘¤ [Applicant] 3/3 JSON íŒŒì‹± ì™„ë£Œ")
            logger.info(f"ğŸ‘¤ [Applicant] âœ… ë¶„ì„ ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {time.time() - total_start:.1f}ì´ˆ")

            return result

        finally:
            # 6. ì •ë¦¬: Geminiì—ì„œ íŒŒì¼ ì‚­ì œ
            if self._uploaded_file:
                logger.debug("ğŸ‘¤ [Applicant] Gemini íŒŒì¼ ì‚­ì œ ì¤‘...")
                loader.delete_file(self._uploaded_file)
                self._uploaded_file = None

    async def analyze_local_pdfs(self, file_paths: list[str]) -> dict[str, Any]:
        """
        ë¡œì»¬ PDF íŒŒì¼ë“¤ í†µí•© ë¶„ì„ (Gemini Files API ì§ì ‘ ì‚¬ìš©)

        ì—¬ëŸ¬ PDF(ì´ë ¥ì„œ, í¬íŠ¸í´ë¦¬ì˜¤, ìê¸°ì†Œê°œì„œ)ë¥¼ í•˜ë‚˜ì˜ Gemini ìš”ì²­ìœ¼ë¡œ í†µí•© ë¶„ì„

        Args:
            file_paths: ë¡œì»¬ PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

        Returns:
            êµ¬ì§ì í”„ë¡œí•„ ë¶„ì„ ê²°ê³¼ (JSON)
        """
        from google import genai
        from google.genai import types
        from pathlib import Path

        loader = self._get_local_loader()

        try:
            # 1. ëª¨ë“  PDFë¥¼ Geminiì— ì—…ë¡œë“œ
            self._uploaded_files = loader.load_files(file_paths)

            # ì—…ë¡œë“œ ìƒíƒœ í™•ì¸
            for uploaded_file in self._uploaded_files:
                if uploaded_file.state != 'ACTIVE':
                    raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {uploaded_file.display_name} - {uploaded_file.state}")

            # 2. ìŠ¤í‚¤ë§ˆ ë¡œë“œ (Gemini ì§ì ‘ ì‚¬ìš©ì´ë¯€ë¡œ ì´ìŠ¤ì¼€ì´í”„ ë¶ˆí•„ìš”)
            schema = get_schema_for_prompt("applicant_schema", escape_braces=False)

            # 3. íŒŒì¼ ëª©ë¡ ì„¤ëª… ìƒì„±
            file_descriptions = []
            for i, uploaded_file in enumerate(self._uploaded_files, 1):
                filename = uploaded_file.display_name
                # íŒŒì¼ëª…ì—ì„œ ë¬¸ì„œ ìœ í˜• ì¶”ì¸¡
                if "ì´ë ¥ì„œ" in filename or "resume" in filename.lower():
                    doc_type = "ì´ë ¥ì„œ (Resume)"
                elif "í¬íŠ¸í´ë¦¬ì˜¤" in filename or "portfolio" in filename.lower():
                    doc_type = "í¬íŠ¸í´ë¦¬ì˜¤ (Portfolio)"
                elif "ìê¸°ì†Œê°œì„œ" in filename or "essay" in filename.lower() or "ìì†Œì„œ" in filename:
                    doc_type = "ìê¸°ì†Œê°œì„œ (Personal Statement)"
                else:
                    doc_type = "ê¸°íƒ€ ë¬¸ì„œ"
                file_descriptions.append(f"{i}. {filename} - {doc_type}")

            files_summary = "\n".join(file_descriptions)

            # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""{applicant_analyze.SYSTEM_MESSAGE}

Analyze the following attached PDF documents for this candidate:

{files_summary}

## Output JSON Schema
{schema}

Instructions:
- Integrate information from ALL provided documents (resume, portfolio, essay)
- Use doc_id in evidence to specify which document the quote is from
- Score each axis based on combined evidence from all documents
- If information is not explicitly stated in any document, mark as "unknown"

Output MUST be valid JSON only. No markdown, no explanations."""

            # 5. Geminiì— ëª¨ë“  PDF + í”„ë¡¬í”„íŠ¸ ì „ì†¡
            client = genai.Client(api_key=GOOGLE_API_KEY)

            # contents ë°°ì—´ êµ¬ì„±: [íŒŒì¼1 Part, íŒŒì¼2 Part, ..., í”„ë¡¬í”„íŠ¸]
            # URI ë¬¸ìì—´ì´ ì•„ë‹Œ types.Part.from_uri()ë¡œ ë³€í™˜í•´ì•¼ Geminiê°€ PDFë¥¼ ì¸ì‹í•¨
            contents = [
                types.Part.from_uri(file_uri=uploaded_file.uri, mime_type="application/pdf")
                for uploaded_file in self._uploaded_files
            ]
            contents.append(prompt)

            response = client.models.generate_content(
                model=self.model_name,
                contents=contents
            )

            # 6. JSON íŒŒì‹±
            result = parse_json_response(response.text)

            return result

        finally:
            # 7. ì •ë¦¬: Geminiì—ì„œ ëª¨ë“  íŒŒì¼ ì‚­ì œ
            if self._uploaded_files:
                loader.delete_files(self._uploaded_files)
                self._uploaded_files = []

    async def run_from_local_pdfs(
        self,
        file_paths: list[str],
        candidate_name: Optional[str] = None
    ) -> dict[str, Any]:
        """
        ë¡œì»¬ PDF ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        ì—¬ëŸ¬ PDF(ì´ë ¥ì„œ, í¬íŠ¸í´ë¦¬ì˜¤, ìê¸°ì†Œê°œì„œ)ë¥¼ í†µí•© ë¶„ì„

        Args:
            file_paths: ë¡œì»¬ PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            candidate_name: êµ¬ì§ìëª… (ì˜µì…˜)

        Returns:
            ìµœì¢… ë¶„ì„ ê²°ê³¼
        """
        from pathlib import Path

        # 1. PDF í†µí•© ë¶„ì„
        profile = await self.analyze_local_pdfs(file_paths)

        # 2. ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        profile["_source"] = {
            "type": "local_pdfs",
            "files": [Path(p).name for p in file_paths],
        }

        # 3. DB ì €ì¥ (ì˜µì…˜)
        if self.save_to_db and self.db:
            doc_id = self.db.save_applicant_profile(profile)
            profile["_id"] = doc_id

        return profile

    async def run(
        self,
        resume_text: str,
        candidate_name: Optional[str] = None
    ) -> dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            resume_text: ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ í…ìŠ¤íŠ¸
            candidate_name: êµ¬ì§ìëª… (ì˜µì…˜, ì—†ìœ¼ë©´ ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì¶œ)

        Returns:
            ìµœì¢… ë¶„ì„ ê²°ê³¼
        """
        # 1. í”„ë¡œí•„ ë¶„ì„
        profile = await self.analyze(resume_text)

        # 2. DB ì €ì¥ (ì˜µì…˜)
        if self.save_to_db and self.db:
            doc_id = self.db.save_applicant_profile(profile)
            profile["_id"] = doc_id

        return profile

    async def run_from_s3(
        self,
        s3_key: str,
        candidate_name: Optional[str] = None
    ) -> dict[str, Any]:
        """
        S3 PDF ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            s3_key: S3 ê°ì²´ í‚¤ (ì˜ˆ: "{token}/resume.pdf")
            candidate_name: êµ¬ì§ìëª… (ì˜µì…˜)

        Returns:
            ìµœì¢… ë¶„ì„ ê²°ê³¼
        """
        # 1. PDF ë¶„ì„
        profile = await self.analyze_pdf(s3_key)

        # 2. ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        profile["_source"] = {
            "type": "s3_pdf",
            "s3_key": s3_key,
        }

        # 3. DB ì €ì¥ (ì˜µì…˜)
        if self.save_to_db and self.db:
            doc_id = self.db.save_applicant_profile(profile)
            profile["_id"] = doc_id

        return profile

    async def run_from_file(self, file_path: str) -> dict[str, Any]:
        """
        ë¡œì»¬ íŒŒì¼ì—ì„œ ì´ë ¥ì„œ ë¡œë“œ í›„ ë¶„ì„

        Args:
            file_path: ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œ (txt, md ë“±)

        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        with open(file_path, "r", encoding="utf-8") as f:
            resume_text = f.read()

        return await self.run(resume_text)

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.db:
            self.db.close()
